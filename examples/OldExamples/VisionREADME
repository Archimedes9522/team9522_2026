//Aiming at a target

Now that you have properly set up your vision system and have tuned a pipeline, you can now aim your robot at an AprilTag using the data from PhotonVision. The yaw of the target is the critical piece of data that will be needed first.

Yaw is reported to the roboRIO over Network Tables. PhotonLib, our vender dependency, is the easiest way to access this data. The documentation for the Network Tables API can be found here and the documentation for PhotonLib here.

In this example, while the operator holds a button down, the robot will turn towards the AprilTag using the P term of a PID loop. To learn more about how PID loops work, how WPILib implements them, and more, visit Advanced Controls (PID) and PID Control in WPILib.

@Override
public void teleopPeriodic() {
    // Calculate drivetrain commands from Joystick values
    double forward = -controller.getLeftY() * Constants.Swerve.kMaxLinearSpeed;
    double strafe = -controller.getLeftX() * Constants.Swerve.kMaxLinearSpeed;
    double turn = -controller.getRightX() * Constants.Swerve.kMaxAngularSpeed;

    // Read in relevant data from the Camera
    boolean targetVisible = false;
    double targetYaw = 0.0;
    var results = camera.getAllUnreadResults();
    if (!results.isEmpty()) {
        // Camera processed a new frame since last
        // Get the last one in the list.
        var result = results.get(results.size() - 1);
        if (result.hasTargets()) {
            // At least one AprilTag was seen by the camera
            for (var target : result.getTargets()) {
                if (target.getFiducialId() == 7) {
                    // Found Tag 7, record its information
                    targetYaw = target.getYaw();
                    targetVisible = true;
                }
            }
        }
    }

    // Auto-align when requested
    if (controller.getAButton() && targetVisible) {
        // Driver wants auto-alignment to tag 7
        // And, tag 7 is in sight, so we can turn toward it.
        // Override the driver's turn command with an automatic one that turns toward the tag.
        turn = -1.0 * targetYaw * VISION_TURN_kP * Constants.Swerve.kMaxAngularSpeed;
    }

    // Command drivetrain motors based on target speeds
    drivetrain.drive(forward, strafe, turn);

    // Put debug information to the dashboard
    SmartDashboard.putBoolean("Vision Target Visible", targetVisible);
}

//Combining Aiming and Getting in Range
Now that you know how to aim toward the AprilTag, let’s also drive the correct distance from the AprilTag.

To do this, we’ll use the pitch of the target in the camera image and trigonometry to figure out how far away the robot is from the AprilTag. Then, like before, we’ll use the P term of a PID controller to drive the robot to the correct distance.

  // Calculate drivetrain commands from Joystick values
  double forward = -controller.getLeftY() * Constants.Swerve.kMaxLinearSpeed;
  double strafe = -controller.getLeftX() * Constants.Swerve.kMaxLinearSpeed;
  double turn = -controller.getRightX() * Constants.Swerve.kMaxAngularSpeed;

  // Read in relevant data from the Camera
  boolean targetVisible = false;
  double targetYaw = 0.0;
  double targetRange = 0.0;
  var results = camera.getAllUnreadResults();
  if (!results.isEmpty()) {
      // Camera processed a new frame since last
      // Get the last one in the list.
      var result = results.get(results.size() - 1);
      if (result.hasTargets()) {
          // At least one AprilTag was seen by the camera
          for (var target : result.getTargets()) {
              if (target.getFiducialId() == 7) {
                  // Found Tag 7, record its information
                  targetYaw = target.getYaw();
                  targetRange =
                          PhotonUtils.calculateDistanceToTargetMeters(
                                  0.5, // Measured with a tape measure, or in CAD.
                                  1.435, // From 2024 game manual for ID 7
                                  Units.degreesToRadians(-30.0), // Measured with a protractor, or in CAD.
                                  Units.degreesToRadians(target.getPitch()));

                  targetVisible = true;
              }
          }
      }
  }

  // Auto-align when requested
  if (controller.getAButton() && targetVisible) {
      // Driver wants auto-alignment to tag 7
      // And, tag 7 is in sight, so we can turn toward it.
      // Override the driver's turn and fwd/rev command with an automatic one
      // That turns toward the tag, and gets the range right.
      turn =
              (VISION_DES_ANGLE_deg - targetYaw) * VISION_TURN_kP * Constants.Swerve.kMaxAngularSpeed;
      forward =
              (VISION_DES_RANGE_m - targetRange) * VISION_STRAFE_kP * Constants.Swerve.kMaxLinearSpeed;
  }

  // Command drivetrain motors based on target speeds
  drivetrain.drive(forward, strafe, turn);

  //Using WPILib Pose Estimation, Simulation, and PhotonVision Together
  This example demonstrates integration of swerve drive control, a basic swerve physics simulation, and PhotonLib’s simulated vision system functionality.
  Estimating Pose
    The Drivetrain class includes functionality to fuse multiple sensor readings together (including PhotonVision) into a best-guess of the pose on the field.

    Please reference the WPILib documentation on using the SwerveDrivePoseEstimator class.

    We use the 2024 game’s AprilTag Locations:

    visionSim.addAprilTags(kTagLayout);

    To incorporate PhotonVision, we need to create a PhotonCamera:

    camera = new PhotonCamera(kCameraName);

    During periodic execution, we read back camera results. If we see AprilTags in the image, we calculate the camera-measured pose of the robot and pass it to the Drivetrain.

      // Correct pose estimate with vision measurements
      var visionEst = vision.getEstimatedGlobalPose();
      visionEst.ifPresent(
              est -> {
                  // Change our trust in the measurement based on the tags we can see
                  var estStdDevs = vision.getEstimationStdDevs();

                  drivetrain.addVisionMeasurement(
                          est.estimatedPose.toPose2d(), est.timestampSeconds, estStdDevs);
              });

Simulating the Camera
    First, we create a new VisionSystemSim to represent our camera and coprocessor running PhotonVision, and moving around our simulated field.

      // Create the vision system simulation which handles cameras and targets on the field.
      visionSim = new VisionSystemSim("main");
      // Add all the AprilTags inside the tag layout as visible targets to this simulated field.
      visionSim.addAprilTags(kTagLayout);
      // Create simulated camera properties. These can be set to mimic your actual camera.

      Then, we add configure the simulated vision system to match the camera system being simulated.

        // Create simulated camera properties. These can be set to mimic your actual camera.
        var cameraProp = new SimCameraProperties();
        cameraProp.setCalibration(960, 720, Rotation2d.fromDegrees(90));
        cameraProp.setCalibError(0.35, 0.10);
        cameraProp.setFPS(15);
        cameraProp.setAvgLatencyMs(50);
        cameraProp.setLatencyStdDevMs(15);
        // Create a PhotonCameraSim which will update the linked PhotonCamera's values with visible
        // targets.
        cameraSim = new PhotonCameraSim(camera, cameraProp);
        // Add the simulated camera to view the targets on this simulated field.
        visionSim.addCamera(cameraSim, kRobotToCam);

        cameraSim.enableDrawWireframe(true);

Updating the Simulated Vision System
    During simulation, we periodically update the simulated vision system.

    @Override
    public void simulationPeriodic() {
        // Update drivetrain simulation
        drivetrain.simulationPeriodic();

        // Update camera simulation
        vision.simulationPeriodic(drivetrain.getSimPose());

        var debugField = vision.getSimDebugField();
        debugField.getObject("EstimatedRobot").setPose(drivetrain.getPose());
        debugField.getObject("EstimatedRobotModules").setPoses(drivetrain.getModulePoses());

        // Update gamepiece launcher simulation
        gpLauncher.simulationPeriodic();

        // Calculate battery voltage sag due to current draw
        RoboRioSim.setVInVoltage(
                BatterySim.calculateDefaultBatteryLoadedVoltage(drivetrain.getCurrentDraw()));
    }